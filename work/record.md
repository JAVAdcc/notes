## 2024.12.16

1、关于两篇文章

输入输出？（raster input->vector output吗？不太懂为什么要这么做）

传统的矢量图怎么表征颜色，怎么实现复杂的纹理

一些概念:每个控制点的latent codes，geometric dield（probability field），不是很懂，意思是每个点的latentcode可以表示这个点附近的纹理的概率分布吗

图中的几何形状是怎么找出来的呢

全局的mlp怎么训练出来呢

想要生成清晰锐利的图片会不会很困难

想了解生成传统矢量图的实现过程

2、其他方向在做什么

---

## 2025.1.17

最近基本什么都没干，期末周之前尝试了解一些机器学习的内容，跟着菜鸟教程熟悉了一下torch和简单的神经网络。最近两天开始看了一些nerf的介绍。

---
### 近期方向

1、想要确定一下最近看哪个方向的东西，感觉3D重建的内容看起来挺有意思的，但是不知道具体在往哪些方面做

2、哪些基础内容需要体系化地进行学习

李宏毅，stanford

3、怎么进行一些简单的代码实践，需要掌握哪些工具。

---
### 长期

>**课题组的研究逻辑：**
>其实AI的两个大方向:AIGC和机器人,图像重建最后的目的也是希望落在生成上
>图像的编辑->图像驱动
>视频 将视频压缩成影视场 视频编辑
>生成 
>交互式的编辑 跨图像

4、个人长期的一个规划？
主要取决于个人本科之后的规划,如果出国需要水点论文出来,不过没问关于国内升学的看法,如果留在学校,跟着这个研究的逻辑走也没有问题.不过或许以后再说吧,毕竟暂时还早,可以到大二结束在考虑,另外其实也取决于自己是不是真的适合科研,上手速度怎么样.
所以现在看来,还是把短期的基础内容尽快做好.

## 2.22

目前交到手上的任务是拿现有的程序跑数据集 
其实是挺简单的活，程序的完成度已经是很高了，虽然有一些小问题似乎也都是个人能解决的范围
剩下的问题是跑那个大数据集的时候文件IO还得改一下
需要顺便把os库的东西基本地学一下

不过这样单纯完成任务感觉也不是关键
最重要的是要整理清楚整个程序的逻辑，或者说是这个任务的逻辑
目前是已经粗略地读了single forward的程序 
近期需要整理一下这个函数干的事情 然后是内部meshprocess这个大函数
这些应该都是图形学和计算机视觉的东西 也是一些我完全不了解的东西 最好是能同步进行一些系统性的学习

不过这个倒还不是首要要做的 除了这些 深度学习的内容其实还有一些没搞定 而且学了的也大多是半吊子 我觉得除了上述的一些基本功 这些模型的学习倒是不能落下，虽然在实际工程中未必有很大占比，但是如果不懂就会很难受
何况刚刚开始学了一段时间 感觉还是应该趁热打铁

以及重中之重，主播这个coding能力实在是太弱了

## 3.12

最近几天把VAE看了好多，VAE，vqVAE，CVAE，但是CVAE还不是很明白，感觉有点莫名其妙，然后这个模型说实话在生成方面我理解还不是很深刻，还是等后面任务下来了结合着去想吧。
最近其实课内没什么压力，稍微也有点松散了。
去看那些课其实感觉也没啥动力，李宏毅剩下的课好多还是和大语言相关了，暂时没有特别大兴趣，cs231n感觉好像很基础？？重新看一遍网络的训练和cnn之类东西其实也挺无聊的，我觉得还是实践中比较能加深印象，然后他那个作业吧，我主要有点不懂它整体什么想法，确实是挺偏向于实践的，但是有点盲人摸象的感觉，无从下手，就没什么动力去搞。
今天可能打算看一下那些比较重要的模型吧，之前提到的nerf，instantngp，gaussiansplatting，stablediffusion把论文下下来理解一下
感觉不知道该看什么某种程度上也是因为见识太少了

## 3.20

![alt text](<./image/p3.png>)

1、网格场是什么，之前看VAE的encoder输出的好像是z = mu + sigma * epsilon这种，就不是很明白怎么会输出一个‘网格场’

2、decoder的要求感觉和shapelayer代码里的MLP差不多？（把feature转成rgb）（所以为什么不直接用mlp做呢）  
然后看infd那个论文的框架图就不太懂要参照哪部分(是后面$\phi$->CLIF->output的部分吗)
![alt text](<./image/p4.png>)

3、回过来有点想不通shapelayer做的事情的意义，重建，编辑，但是没办法生成是吗？那shapelayer和这次的任务的关联是什么呢，就是提供了三角化之后的图片吗

## 3.26

需要明确一下思路：

### infd框架外的预处理

首先是数据集下载
> 数据集就会提供图片、目标（鸟）的掩码、名称（caption暂时还没用）

然后数据读取，那就是
- 把mask以外的都设绿
- 对mask用vtracer 存储曲线

最终这一部分要提供给infd两个输入 图片和掩码的曲线

### infd框架内处理 

输入：
- 鸟（背景绿幕）作为vae的输入
- 鸟的mask的对应坐标 用于给渲染器查询掩码内的像素
  
期望输出：
查询的掩码坐标内最终呈现出一只鸟

### 具体的infd训练&推理

diffusion应该不用train 只要输入鸟的图片train一个VAE
把vae的模型参数保存为save/ae_custom下的last-model.pth 

推理阶段就是 输入一张鸟的图片 用预训练的vae生成网格场用掩码的坐标查询对应的rgb 得到输出 改变查询的范围大小 看看输出的变化

**思路问题**
- vae训练比较简单，但是跑推理可能要自己组织一下，infd本身没有设计检验vae的方法，那就要自己加载模型，加载数据，控制查询的像素点，保存输出，感觉都很麻烦

**技术问题**
- 预处理部分图像读取处理输出的操作没实操过，得练一练
- 预处理部分需要看vtracer的用法&如何保存获得的贝赛尔曲线
- 不知道infd渲染部分控制查询坐标的范围是怎么写的（infd训练和生成流程肯定都是直接查整张图的，但是我们的要求好像是查一部份坐标）
- 不太会用贝赛尔曲线 不知道怎么拉扯曲线然后获得曲线内的坐标
- infd数据加载等一系列流程都很不熟悉



